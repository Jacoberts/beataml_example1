{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a baseline model for Subchallenge 1\n",
    "\n",
    "We'll train a RidgeRegression model on RNASeq data for each inhibitor to predict AUC. Specifically:\n",
    "\n",
    "- Select the 1000 highest variance genes\n",
    "- For each inhibitor, train with leave-one-out cross validation\n",
    "- Try a bunch of alpha values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, download training data.\n",
    "\n",
    "This only needs to be run once, to populate the `training/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install synapseclient\n",
    "\n",
    "import getpass\n",
    "import pandas\n",
    "import synapseclient\n",
    "import synapseutils\n",
    "\n",
    "syn = synapseclient.Synapse()\n",
    "syn.login(input(prompt=\"Enter Synapse Username\"), getpass.getpass(\"Enter Synapse Password\"))\n",
    "downloaded_files = synapseutils.syncFromSynapse(syn, 'syn21212904', path='training') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, load the data, and train a model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "rnaseq = pandas.read_csv('training/rnaseq.csv')\n",
    "aucs = pandas.read_csv('training/aucs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import TransposeRnaSeqTable\n",
    "\n",
    "specimens = TransposeRnaSeqTable(rnaseq)\n",
    "selected_genes = specimens.var().nlargest(1000).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%.1f%% of (inhibitor, specimen) pairs have AUCs.\" % (\n",
    "    100 * aucs.shape[0] / float(len(aucs.inhibitor.unique()) * len(aucs.lab_id.unique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "import seaborn\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# Normalize each specimen.\n",
    "X = specimens\n",
    "X = X.div(numpy.linalg.norm(X, axis=1), axis=0)\n",
    "X = X[selected_genes]\n",
    "\n",
    "# Compute z-score.\n",
    "gene_mean = X.mean(axis=0)\n",
    "gene_std = X.std(axis=0)\n",
    "X = (X - gene_mean) / gene_std\n",
    "\n",
    "# For each inhibitor, train a regressor.\n",
    "alphas = numpy.logspace(-1, 5, num=40)\n",
    "regressors = {}\n",
    "for inhibitor in aucs.inhibitor.unique():\n",
    "    auc_subset = aucs[aucs.inhibitor == inhibitor]\n",
    "    regr = RidgeCV(alphas=alphas, store_cv_values=True)\n",
    "    regr = regr.fit(X.loc[auc_subset.lab_id], auc_subset.auc)\n",
    "    regressors[inhibitor] = regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the highest error and lowest error.\n",
    "def plotRegressor(inhibitor, regr):\n",
    "    pyplot.figure()\n",
    "    errors = numpy.sqrt(regr.cv_values_.mean(axis=0))\n",
    "    seaborn.scatterplot(x=alphas, y=errors, label='ridge training error')\n",
    "    pyplot.axhline(\n",
    "        y=aucs[aucs.inhibitor == inhibitor].auc.std(),\n",
    "        label='AUC variance\\n(zero skill prediction)')\n",
    "\n",
    "    # Annotate.\n",
    "    pyplot.xlabel('alpha')\n",
    "    pyplot.ylabel('Cross-Validation RMSE [AUC]')\n",
    "    pyplot.title('%s Ridge Regression training error\\nOptimal alpha: %0.1f\\nMin error: %.3f' % (\n",
    "        inhibitor, regr.alpha_, min(errors)))\n",
    "    pyplot.legend()\n",
    "\n",
    "for inhibitor in aucs.inhibitor.unique()[0:4]:\n",
    "    plotRegressor(inhibitor, regressors[inhibitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the model information in `model/`\n",
    "\n",
    "In python this process is sometimes referred to as \"pickling,\" thus the variable names \"pkl_1\" and \"pkl_2\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_1_dict = {\n",
    "    'gene': selected_genes,\n",
    "    'gene_mean': gene_mean,\n",
    "    'gene_std': gene_std,\n",
    "}\n",
    "for inhibitor, regr in regressors.items():\n",
    "    pkl_1_dict[inhibitor] = regr.coef_\n",
    "pkl_1_out = pandas.DataFrame(pkl_1_dict)\n",
    "\n",
    "pkl_2_out = pandas.DataFrame({\n",
    "    'inhibitor': [inhibitor for inhibitor in regressors.keys()],\n",
    "    'intercept': [regr.intercept_ for regr in regressors.values()],\n",
    "})\n",
    "pkl_1_out.to_csv('model/pkl_1.csv', index=False)\n",
    "pkl_2_out.to_csv('model/pkl_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model\n",
    "\n",
    "We run the model with\n",
    "\n",
    "```bash\n",
    "SYNAPSE_PROJECT_ID=<your project ID>\n",
    "docker build -t docker.synapse.org/$SYNAPSE_PROJECT_ID/sc1_model .\n",
    "docker run \\\n",
    "    -v \"$PWD/training/:/input/\" \\\n",
    "    -v \"$PWD/output:/output/\" \\\n",
    "    docker.synapse.org/$SYNAPSE_PROJECT_ID/sc1_model\n",
    "\n",
    "# Maybe push to Synapse.\n",
    "docker login docker.synapse.org\n",
    "docker push docker.synapse.org/$SYNAPSE_PROJECT_ID/sc1_model\n",
    "```\n",
    "**Note: you must pass the Synapse [certified user test](https://docs.synapse.org/articles/accounts_certified_users_and_profile_validation.html#certified-users) before you can push to the Synapse docker hub.",
    "\n",
    "### Look at predictions vs goldstandard for training data\n",
    "\n",
    "Assumes predictions are in `output/predictions.csv`. Note that the performance on training dataset is going to be better than on the leaderboard data. Therefore, this is a good test of formatting / sanity check, but not of predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join groundtruth onto predictions, because predictions is a\n",
    "# superset of groundtruth.\n",
    "indices = ['lab_id', 'inhibitor']\n",
    "groundtruth = pandas.read_csv('training/aucs.csv').set_index(indices)\n",
    "predictions = pandas.read_csv('output/predictions.csv').set_index(indices)\n",
    "predictions_and_groundtruth = groundtruth.join(\n",
    "    predictions, lsuffix='_groundtruth', rsuffix='_prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.scatterplot(\n",
    "    x='auc_groundtruth',\n",
    "    y='auc_prediction',\n",
    "    data=predictions_and_groundtruth,\n",
    "    alpha=0.05)\n",
    "pyplot.title('SC1 baseline predictor')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
